{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset location\n",
    "covid_path = 'dataset/covid/'\n",
    "non_covid_path = 'dataset/no_covid/'\n",
    "\n",
    "base_directory = 'dataset/cross_validation/'\n",
    "test_directory = 'dataset/cross_validation_test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function has been adapted from the \n",
    "# https://github.com/sagihaider/TransferLearning_COVID19 github repo created by Dr. Haider\n",
    "def rename_dataset_files(path, class_handler):\n",
    "    for count, filename in enumerate(os.listdir(path)): \n",
    "        dst = class_handler + \"-\" + str(count) + \".png\"\n",
    "        src = path + filename \n",
    "        dst = path + dst \n",
    "        \n",
    "        os.rename(src, dst)\n",
    "    \n",
    "    print(class_handler, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noncovid 396\n"
     ]
    }
   ],
   "source": [
    "rename_dataset_files(covid_path, \"covid\")\n",
    "rename_dataset_files(non_covid_path, \"noncovid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create folders for the dataset split\n",
    "if not os.path.exists(base_directory):\n",
    "    os.mkdir(base_directory)\n",
    "    \n",
    "if not os.path.exists(test_directory):\n",
    "    os.mkdir(test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the files from the full dataset into custom destinations and ranges\n",
    "def copy_files_from_dataset(source, destination, fname_format, lower_limit, upper_limit):\n",
    "    fnames = [fname_format.format(i) for i in range(lower_limit, upper_limit)]\n",
    "    \n",
    "    for fname in fnames: \n",
    "        src = os.path.join(source, fname)\n",
    "        dst = os.path.join(destination, fname)\n",
    "        \n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy covid\n",
    "copy_files_from_dataset(covid_path, base_directory, 'covid-{}.png', 0, 300)\n",
    "copy_files_from_dataset(covid_path, test_directory, 'covid-{}.png', 300, 348)\n",
    "\n",
    "# copy non-covid\n",
    "copy_files_from_dataset(non_covid_path, base_directory, 'noncovid-{}.png', 0, 300)\n",
    "copy_files_from_dataset(non_covid_path, test_directory, 'noncovid-{}.png', 300, 348)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "\n",
    "import os\n",
    "\n",
    "IMG_SIZE = 227 # alexnet image size\n",
    "\n",
    "num_folds = 5\n",
    "\n",
    "no_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these functions have been taken from the \n",
    "# https://github.com/sagihaider/TransferLearning_COVID19 github repo created by Dr. Haider\n",
    "def label_img(img):\n",
    "    word_label = img.split('-')[0]\n",
    "    if word_label == 'covid': return 1\n",
    "    elif word_label == 'noncovid': return 0\n",
    "    \n",
    "    \n",
    "def createDataSplitSet(datapath):\n",
    "    X=[]\n",
    "    y=[]\n",
    "\n",
    "    for img in os.listdir(datapath):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(datapath, img)\n",
    "        image = cv2.resize(cv2.imread(path), (IMG_SIZE, IMG_SIZE))\n",
    "        image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "\n",
    "        X.append(np.array(image))\n",
    "        y.append(label)\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 227, 227, 3)\n",
      "(96, 227, 227, 3)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y = createDataSplitSet(base_directory) # train_dataset # capital 'X'\n",
    "test_X, test_y = createDataSplitSet(test_directory) # test_dataset # capital 'X'\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 6s 264ms/step - loss: 2.2061 - acc: 0.5771\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 6s 261ms/step - loss: 0.9997 - acc: 0.6104\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 6s 262ms/step - loss: 0.8239 - acc: 0.6500\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 6s 262ms/step - loss: 0.6795 - acc: 0.6875\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 6s 262ms/step - loss: 0.6259 - acc: 0.7250\n",
      "[0.8456728458404541, 0.625]\n"
     ]
    }
   ],
   "source": [
    "# alexnet crossvalidation training\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "# Define per-fold score containers\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "test_acc_per_fold = []\n",
    "precision_per_fold = []\n",
    "recall_per_fold = []\n",
    "f1score_per_fold = []\n",
    "auc_per_fold = []\n",
    "\n",
    "# k-means cross-validation for alexnet with a k-value of 5\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(train_X, train_y):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation='relu',\n",
    "                            input_shape=(227, 227, 3)),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "        keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "        keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(filters=384, kernel_size=(1, 1), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.Conv2D(filters=256, kernel_size=(1, 1), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "        keras.layers.BatchNormalization(),\n",
    "        keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation='relu', name='fc1'),\n",
    "        keras.layers.Dropout(0.1),\n",
    "        keras.layers.Dense(64, activation='relu', name='fc2'),\n",
    "        keras.layers.Dropout(0.1),\n",
    "        keras.layers.Dense(1, activation='sigmoid', name='output')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "    \n",
    "    history = model.fit(train_X[train], train_y[train],\n",
    "                                  batch_size=20,\n",
    "                                  epochs=no_epochs)\n",
    "    \n",
    "    # Generate generalization metrics\n",
    "    scores = model.evaluate(train_X[test], train_y[test], verbose=0)\n",
    "    \n",
    "    print(f'Score for fold {fold_no}:')    \n",
    "    \n",
    "    # These metrics have been taken from the \n",
    "    # https://github.com/sagihaider/TransferLearning_COVID19 github repo created by Dr. Haider\n",
    "    predictions = model.predict(test_X)\n",
    "    ypred = predictions > 0.5\n",
    "    test_acc = accuracy_score(test_y, ypred)\n",
    "\n",
    "    precision, recall, f1score, _ = precision_recall_fscore_support(test_y, ypred, average='binary')\n",
    "\n",
    "    auc = roc_auc_score(test_y, ypred)\n",
    "    \n",
    "    print(\"Train Accuray:\\t\", scores[1])\n",
    "    print(\"Loss:\\t\\t\", scores[0])\n",
    "    print(\"Test Accuracy:\\t\", test_acc)\n",
    "    print(\"Precision:\\t\", precision)\n",
    "    print(\"Recall:\\t\\t\", recall)\n",
    "    print(\"F1 Score:\\t\", f1score)\n",
    "    print(\"AUC:\\t\\t\", auc)\n",
    "    \n",
    "    acc_per_fold.append(scores[1])\n",
    "    loss_per_fold.append(scores[0])\n",
    "    test_acc_per_fold.append(test_acc)\n",
    "    precision_per_fold.append(precision)\n",
    "    recall_per_fold.append(recall)\n",
    "    f1score_per_fold.append(f1score)\n",
    "    auc_per_fold.append(auc)\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss:          2.7427515983581543\n",
      ">        - Accuracy:      0.5083333253860474\n",
      ">        - Test Accuracy: 0.5208333333333334\n",
      ">        - Precision:     0.5106382978723404\n",
      ">        - Recall:        1.0\n",
      ">        - F1 score:      0.676056338028169\n",
      ">        - AUC:           0.5208333333333333\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss:          2.196779489517212\n",
      ">        - Accuracy:      0.49166667461395264\n",
      ">        - Test Accuracy: 0.5104166666666666\n",
      ">        - Precision:     0.5052631578947369\n",
      ">        - Recall:        1.0\n",
      ">        - F1 score:      0.6713286713286714\n",
      ">        - AUC:           0.5104166666666667\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss:          3.4329965114593506\n",
      ">        - Accuracy:      0.5083333253860474\n",
      ">        - Test Accuracy: 0.5104166666666666\n",
      ">        - Precision:     0.5052631578947369\n",
      ">        - Recall:        1.0\n",
      ">        - F1 score:      0.6713286713286714\n",
      ">        - AUC:           0.5104166666666667\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss:          1.557428002357483\n",
      ">        - Accuracy:      0.5666666626930237\n",
      ">        - Test Accuracy: 0.59375\n",
      ">        - Precision:     0.5517241379310345\n",
      ">        - Recall:        1.0\n",
      ">        - F1 score:      0.7111111111111111\n",
      ">        - AUC:           0.59375\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss:          0.9044564366340637\n",
      ">        - Accuracy:      0.5333333611488342\n",
      ">        - Test Accuracy: 0.5625\n",
      ">        - Precision:     0.5405405405405406\n",
      ">        - Recall:        0.8333333333333334\n",
      ">        - F1 score:      0.6557377049180328\n",
      ">        - AUC:           0.5625\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy:      0.5216666698455811 (+- 0.02614064614766121)\n",
      "> Loss:          2.166882407665253\n",
      "> Test Accuracy: 0.5395833333333333\n",
      "> Precision:     0.5226858584266779\n",
      "> Recall:        0.9666666666666666\n",
      "> F1 score:      0.677112499342931\n",
      "> AUC:           0.5395833333333334\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss:          {loss_per_fold[i]}')\n",
    "    print(f'>        - Accuracy:      {acc_per_fold[i]}')\n",
    "    print(f'>        - Test Accuracy: {test_acc_per_fold[i]}')\n",
    "    print(f'>        - Precision:     {precision_per_fold[i]}')\n",
    "    print(f'>        - Recall:        {recall_per_fold[i]}')\n",
    "    print(f'>        - F1 score:      {f1score_per_fold[i]}')\n",
    "    print(f'>        - AUC:           {auc_per_fold[i]}')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy:      {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss:          {np.mean(loss_per_fold)}')\n",
    "print(f'> Test Accuracy: {np.mean(test_acc_per_fold)}')\n",
    "print(f'> Precision:     {np.mean(precision_per_fold)}')\n",
    "print(f'> Recall:        {np.mean(recall_per_fold)}')\n",
    "print(f'> F1 score:      {np.mean(f1score_per_fold)}')\n",
    "print(f'> AUC:           {np.mean(auc_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
